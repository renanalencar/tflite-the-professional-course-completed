{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Week 3.ipynb","provenance":[{"file_id":"1A9mX4v7D1Ur7S6w_eMHqhT8vCxtl0Cnf","timestamp":1658663952789}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hd4i8IvSHe2N"},"source":["\n","\n","```\n","# This is formatted as code\n","```\n","\n","# Week 3 - Model Optimizations\n","\n","## Indroduction\n","\n","In this appendix, you will learn how to apply different optimization types, such as quantization, clustering, and pruning.\n","\n","This appendix uses the following development tools (sorted by greater relevance):\n","\n","*   TensorFlow 2.x (latest)\n","*   TensorFlow Datasets (latest)\n","*   Matplotlib (latest)\n","*   Python 3.x (latest)"]},{"cell_type":"markdown","metadata":{"id":"8uWdxnd1J_TT"},"source":["# Training the model\n","\n","\n","First of all, we need to install TensorFlow 2.x (its latest version at the time you follow this tutorial) and download one of the trained TensorFlow models provided at TensorFlow Hub.\n","\n","Those steps are implemented below:"]},{"cell_type":"code","metadata":{"id":"vdf8E13eKfe3"},"source":["# Installing TensorFlow 2.x\n","!pip install tensorflow\n","!pip install --upgrade tensorflow-datasets"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7qxfEu0LUst5"},"source":["## Setup input pipeline\n","First, we need to download the stanford_dogs dataset to train our model."]},{"cell_type":"code","metadata":{"id":"zhZ4rPFshe_W"},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vNVluEtGU91v"},"source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import matplotlib.pyplot as plt\n","\n","# use tensorflow_datasets library to easily download the dataset StanfordDogs\n","dataset, ds_info = tfds.load(\"stanford_dogs\", with_info=True)\n","training_data, test_data = dataset[\"train\"], dataset[\"test\"]\n","\n","# plot some image samples from the training data\n","tfds.show_examples(training_data, ds_info)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uPznkGVnaFTi"},"source":["## Preprocess the dataset\n","\n","Once we have the dataset, we need to convert them to the input format our model supports."]},{"cell_type":"code","metadata":{"id":"tVb9EroHaZcu","executionInfo":{"status":"error","timestamp":1653948008792,"user_tz":180,"elapsed":5,"user":{"displayName":"Luiz Vitor Reis","userId":"14650443822133367941"}},"outputId":"faeba624-ff2b-4166-ebc4-e73a7b76838b","colab":{"base_uri":"https://localhost:8080/","height":223}},"source":["IMAGE_SIZE = 224\n","BATCH_SIZE = 32\n","\n","def preprocess(sample):\n","  \"\"\" Convert image from int to float, normalize it and resize it. \"\"\"\n","  image, label = sample['image'], sample['label']\n","  image = tf.cast(image, tf.float32) / 255.\n","  image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n","  return image, label\n","\n","def prepare(dataset):\n","    ds = dataset.map(preprocess, num_parallel_calls=4)\n","    ds = ds.shuffle(buffer_size=1000)\n","    ds = ds.batch(BATCH_SIZE)\n","    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","    return ds\n","\n","training_batches = prepare(training_data)\n","test_batches = prepare(test_data)\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-98c5f5bfa5cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtraining_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mtest_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'training_data' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"V0QMAGNPJGVz"},"source":["## Create the classification model\n","\n","Now we can create the classification model using the MobileNetV2 network developed by Google and pretrained on ImageNet."]},{"cell_type":"code","metadata":{"id":"kVsIrz8gJTHJ"},"source":["\n","\n","IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n","\n","# Create the base model from the pre-trained model MobileNet V2\n","base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n","                                              include_top=False, \n","                                              weights='imagenet')\n","print('Classification model finished')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"43bvybQAnuRj"},"source":["Once we have our base model, we freeze its layers and add an MLP top layer on its top, which is going to be fine-tuned during the model training."]},{"cell_type":"code","metadata":{"id":"DmYVGceKn9LM"},"source":["base_model.trainable = False\n","NUM_CLASSES = ds_info.features['label'].num_classes\n","model = tf.keras.Sequential([\n","  base_model,\n","  tf.keras.layers.GlobalAveragePooling2D(),\n","  tf.keras.layers.BatchNormalization(),\n","  tf.keras.layers.Dense(512, activation='elu'),\n","  tf.keras.layers.Dense(256, activation='elu'),\n","  tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TWB0oo7gpSyY"},"source":["Finally, we can compile our whole model."]},{"cell_type":"code","metadata":{"id":"ILILYJdapaDb"},"source":["model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RF_kIh2OqBZp"},"source":["## Train and test model\n","To train our model, we only need to rely on Keras' fit() method.\n","\n"]},{"cell_type":"code","metadata":{"id":"458QbEDbqLSE"},"source":["# This callback will stop the training when there is no improvement in \n","# the validation accuracy for three consecutive epochs. \n","callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n","\n","# train model\n","history = model.fit(training_batches,\n","                    epochs=30,\n","                    validation_data=test_batches,\n","                    callbacks=[callback])\n","\n","print('Model trained')\n","\n","# plot accuracy during training\n","plt.plot(history.history['accuracy'], label='Training accuracy')\n","plt.plot(history.history['val_accuracy'], label='Test accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend()\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nnP2ZXdC3TDb"},"source":["Let's save the model"]},{"cell_type":"code","metadata":{"id":"t0QOBh-s1MHh"},"source":["model.save(\"trained_model_dogs\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtlKs5dSMgHX"},"source":["import shutil\n","shutil.make_archive(\"quantized_models\", 'zip', \"quantized_models\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Jn8J18a-bFq"},"source":["import zipfile\n","with zipfile.ZipFile(\"trained_model_dogs.zip\", 'r') as zip_ref:\n","    zip_ref.extractall(\"model\")\n","print('File has been extracted')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-jtldcwATLm"},"source":["from tensorflow import keras\n","model = keras.models.load_model('model')\n","print('Model loaded')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"izsrPjFbGRml"},"source":["\n","# **Model Quantization**\n","\n","---\n","\n","\n","* Post-training quantization is a conversion technique that can reduce model size;\n","\n","* Furthermore, it's possible to improve CPU and hardware accelerator latency, with little degradation in model accuracy;\n","\n","* Instead of representing the neural network parameters using float 32 bit, we can choose another data type to represent these values, such as integer 8 bits, float 32 bits, etc.\n","\n","* References: \n","\n","  [Model Optimization Overview](https://www.tensorflow.org/lite/performance/model_optimization)\n","\n","  [Post-training Quantization](https://www.tensorflow.org/lite/performance/post_training_quantization)\n","\n","  [Dynamic Range Quantization](https://www.tensorflow.org/lite/performance/post_training_quant)\n","\n","  [Float 16 Quantization](https://www.tensorflow.org/lite/performance/post_training_float16_quant)\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DS-ph6pLZzq6"},"source":["## Dynamic range quantization\n","\n","The simplest form of post-training quantization statically quantizes only the weights from floating-point to integer, which has 8-bits of precision:"]},{"cell_type":"code","metadata":{"id":"RtYRSCtLaAmW"},"source":["converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","tflite_quantized_model = converter.convert()\n","quantization_type = 'dynamic_range'\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aljAQdD0ZqbM"},"source":["## Full integer quantization\n","\n","*   You can improve the latency and reduce even more the model size using the full quantization, in this case all parameters will be quantized instead of just the weights. \n","\n","*   This quantization type requires calibration data.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Mg81kEVmVLgm"},"source":["### Calibration Data\n","\n","* For full integer quantization, you need to calibrate or estimate the range, i.e, (min, max) of all floating-point tensors in the model. \n","\n","* Unlike constant tensors such as weights and biases, variable tensors such as model input, activations (outputs of intermediate layers) and model output cannot be calibrated unless we run a few inference cycles. \n","\n","* As a result, the converter requires a representative dataset to calibrate them. This dataset can be a small subset (about ~100-500 samples) of the training or validation data.\n"]},{"cell_type":"code","metadata":{"id":"2EDZuvd6VJvj"},"source":["# In this case, we are using 100 samples of the training dataset\n","calibration_data = []\n","\n","for counter, image in enumerate(training_batches):\n","  if counter < 100:\n","    calibration_data.append(image[0])\n","    \n","def dataset_gen():\n","  for data in calibration_data:\n","    yield[data]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zSX2_3ss_XhV"},"source":["Loading our model:"]},{"cell_type":"code","metadata":{"id":"pGKz9JCgGZVk"},"source":["converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","\n","converter.experimental_new_converter = True\n","converter.allow_custom_ops = True\n","\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6sxL5MamUyiD"},"source":["### Quantization int 8 bits\n","\n","In this case, we are changing the float 32 bits parameters to integer 8 bits parameters.\n","\n","The greatest accuracy loss."]},{"cell_type":"code","metadata":{"id":"IVfwoUoqUmoL"},"source":["converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n","quantization_type = 'int8'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zv4dfRpSU9bz"},"source":["### Quantization int 8 and int 16\n","In this case, we are changing the float 32 bits parameters to integer 8 bits parameters for the weights and integer 16 bits to activations.\n","\n","The accuracy loss is smaller than in the last case."]},{"cell_type":"code","metadata":{"id":"KuvapQZjVEQ7"},"source":[" converter.target_spec.supported_ops = [tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8, tf.lite.OpsSet.SELECT_TF_OPS]\n"," quantization_type = 'int8x16'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UkxVqmK0U2HX"},"source":["### Quantization float 16 bits\n","\n","In this case, we are changing the parameters from float 32 bits parameters to float 16 bits parameters.\n","\n","The smallest accuracy loss."]},{"cell_type":"code","metadata":{"id":"49OYcQ0wUudU"},"source":["converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n","converter.target_spec.supported_types = [tf.float16]\n","quantization_type = 'float16'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wdf5xX7jCNBX"},"source":["## Converting the Quantized model to TF Lite"]},{"cell_type":"markdown","metadata":{"id":"XvlY9Jya3ZsQ"},"source":["Here we use the calibration data before conversion:"]},{"cell_type":"code","metadata":{"id":"_z91ITijVRP3"},"source":["converter.representative_dataset = dataset_gen"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tzbQFZv1CQ4n"},"source":["tflite_quantized_model = converter.convert()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m_2rWXOPE74x"},"source":["## Testing the TF Lite model\n","Finally, we can run the converted TF Lite model. "]},{"cell_type":"code","metadata":{"id":"7BvlBtgyFG0u"},"source":["import numpy as np\n","\n","# Creating TF Lite interpreter\n","interpreter = tf.lite.Interpreter(model_content=tflite_quantized_model)\n","\n","# Creating random input data\n","input_details = interpreter.get_input_details()\n","input_shape = input_details[0]['shape']\n","input_data = tf.convert_to_tensor(np.array(np.random.random_sample(input_shape), dtype=np.float32))\n","\n","# Performing inference\n","interpreter.allocate_tensors()\n","interpreter.set_tensor(input_details[0]['index'], input_data)\n","interpreter.invoke()\n","\n","# Getting model's output\n","output_details = interpreter.get_output_details()\n","output = interpreter.get_tensor(output_details[0]['index'])\n","print(\"Input shape: \")\n","print(input_shape)\n","print(\"Model output shape:\")\n","print(output.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v24-bmvamVbb"},"source":["## Saving the TF Lite Model\n","Finally, the last step is to export the TF Lite model as a .tflite file, so it can be embedded on the edge device for inference. "]},{"cell_type":"code","metadata":{"id":"EzS0k7ftBZzD"},"source":["import os\n","if not os.path.exists(\"quantized_models\"):\n","  os.makedirs(\"quantized_models\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eb5pwSIonm26"},"source":["with open(f'quantized_models/quantized_model_{quantization_type}.tflite', 'wb') as f:\n","  f.write(tflite_quantized_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TGtD8mvtqD8k"},"source":["# **Weight Clustering**\n","\n","---\n","\n","* Clustering, or weight sharing, reduces the number of unique weight values in a model;\n","\n","* It first groups the weights of each layer into N clusters, then shares the cluster's centroid value for all the weights belonging to the cluster.\n","\n","* References: \n","\n","  [Weight Clustering Overview](https://www.tensorflow.org/model_optimization/guide/clustering)\n","\n","  [Weight Clustering Example](https://www.tensorflow.org/lite/performance/post_training_quantization)\n","\n"]},{"cell_type":"code","metadata":{"id":"ysnv3k93seSC"},"source":["# New package required\n","!pip install tensorflow_model_optimization"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6qhleI25Ojzh"},"source":["First of all, let's evaluate our original model and save the accuracy value to compare later with the accuracy of the model without clustering optimization. "]},{"cell_type":"code","metadata":{"id":"IY5fH4wsPZyq"},"source":["_, baseline_model_accuracy = model.evaluate(\n","    test_batches, verbose=0)\n","print('Baseline test accuracy:', baseline_model_accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gc2jZ9HfQAWH"},"source":["Now, let's start the clustering process."]},{"cell_type":"code","metadata":{"id":"rSBce9rGsWSM"},"source":["import tensorflow_model_optimization as tfmot"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZYDxXW0XELd0"},"source":["Here we select the number of clustering that we want to apply:"]},{"cell_type":"code","metadata":{"id":"U_eBZzhWsGXA"},"source":["# You can use the elbow method to find out the optimal number of clusters\n","number_of_clusters = 16"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OsftmeovEfRK"},"source":["Setting up the clustering parameters:"]},{"cell_type":"code","metadata":{"id":"solS6Yiqsk4W"},"source":[" cluster_weights = tfmot.clustering.keras.cluster_weights\n"," CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n","\n"," clustering_params = {\n","            'number_of_clusters': number_of_clusters,\n","            'cluster_centroids_init': CentroidInitialization.LINEAR\n","        }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ReVVcUuZEt88"},"source":["Let's apply the pruning just in the following layers: Dense"]},{"cell_type":"code","metadata":{"id":"GbgiwVads6wz"},"source":["def apply_clustering_to_desired_layers(layer):\n","  if isinstance(layer, tf.keras.layers.Dense):\n","    return cluster_weights(layer, **clustering_params)\n","  return layer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tdY929bJE1HD"},"source":["Use `tf.keras.models.clone_model` to apply the clustering to previously chosen layers:"]},{"cell_type":"code","metadata":{"id":"kDfBEDZXtDmc"},"source":["clustered_model = tf.keras.models.clone_model(\n","            model,\n","            clone_function=apply_clustering_to_desired_layers,\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"69mbpi1dOkX3"},"source":["Let's check the architecture of these models"]},{"cell_type":"code","metadata":{"id":"3tM4Pm9GFFs2"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hwRo9prkFIYy"},"source":["clustered_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B3r-Ey8nE7AD"},"source":["Use smaller learning rate for fine-tuning the clustered model: "]},{"cell_type":"code","metadata":{"id":"tPBBhcWytakr"},"source":["opt = tf.keras.optimizers.Adam(learning_rate=1e-5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fu9TOEZYE-wU"},"source":["Compile the model for training:"]},{"cell_type":"code","metadata":{"id":"bs7kLcAatmgU"},"source":["clustered_model.compile(\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    optimizer=opt,\n","    metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"04Vh4jYxFE1X"},"source":["Fine-tuning the model:"]},{"cell_type":"code","metadata":{"id":"WeOiJMC_tqij"},"source":["clustered_model.fit(\n","    training_batches,\n","    validation_data=test_batches,\n","    epochs=1,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fYzq0aUJFPtD"},"source":["Let's evaluate the clustering accuracy and compare it with the previous value. If model accuracy drops too low, you can only apply the clustering to a smaller number of layers:"]},{"cell_type":"code","metadata":{"id":"uxpj3lhO3HuR"},"source":["_, clustered_model_accuracy = clustered_model.evaluate(test_batches, verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7dRjL9IgFYlE"},"source":["print('Baseline test accuracy:', baseline_model_accuracy)\n","print('Clustered test accuracy:', clustered_model_accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4h_2nTzZFv6d"},"source":["Removes all variables that clustering needs only during training, such as tf.Variable for storing the cluster centroids and the indices:"]},{"cell_type":"code","metadata":{"id":"_aOy95F13Oji"},"source":["final_model = tfmot.clustering.keras.strip_clustering(clustered_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D0R2rmgTF1KU"},"source":["Convert the clustered model to tflite:"]},{"cell_type":"code","metadata":{"id":"86vfnCCw3eps"},"source":["converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n","converter.experimental_new_converter = True\n","converter.allow_custom_ops = True\n","converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"boSq5pKoF7G3"},"source":["Note that if you want, is possible to apply the quantization after the clustering, it can reduce your model size."]},{"cell_type":"code","metadata":{"id":"70FigEBy3p10"},"source":["quantize = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zjL4s-okDt15"},"source":["import os\n","if not os.path.exists(\"clustered_models\"):\n","  os.makedirs(\"clustered_models\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"67fgicss3nqc"},"source":[" # Quantize the model\n","if quantize is True:\n","    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","    tflite_clustered_and_quantized_model = converter.convert()\n","\n","    with open(f'clustered_models/clustered_and_quantized_model.tflite', 'wb') as f:\n","        f.write(tflite_clustered_and_quantized_model)\n","\n","else:\n","    tflite_clustered_model = converter.convert()\n","\n","    with open(f'clustered_models/clustered_model.tflite', 'wb') as f:\n","       f.write(tflite_clustered_model)\n","\n","print('Clustering finished')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vw0W0KGmdMao"},"source":["# **Model Pruning**\n","\n","---\n","\n","*   The goal of pruning is to reduce the number of parameters and operations of the model;\n","\n","*   Sparse models are easier to compress, and we can skip the zeroes during inference for latency improvements.\n","\n","\n","* References: \n","\n","  [Pruning Overview](https://www.tensorflow.org/model_optimization/guide/pruning)\n","\n","  [Pruning With Keras](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras)\n"]},{"cell_type":"markdown","metadata":{"id":"NNMvodrPYcLg"},"source":["## Packages"]},{"cell_type":"code","metadata":{"id":"wk-3GkPUfJ--"},"source":["!pip install tensorflow_model_optimization"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DJBzYbbbdnd1"},"source":["import tensorflow_model_optimization as tfmot\n","import numpy as np\n","import tempfile"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rOrXE6OlY9rq"},"source":["## Pruning a whole model"]},{"cell_type":"markdown","metadata":{"id":"dMan9CFVtGWN"},"source":["  initial_sparsity: sparsity (%) at which pruning begins."]},{"cell_type":"code","metadata":{"id":"WUGAhqbimy2w"},"source":["initial_sparsity = 0.50"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ATLsOsFAtMGs"},"source":["final_sparsity: sparsity (%) at which pruning ends."]},{"cell_type":"code","metadata":{"id":"kUAbhb5Im0yY"},"source":["final_sparsity = 0.80"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZghZo-HOtP7e"},"source":["begin_step: step at which to begin pruning."]},{"cell_type":"code","metadata":{"id":"MKS9ylp-m86T"},"source":["begin_step = 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LEiJGlyMtT5t"},"source":["end_step: step at which to end pruning."]},{"cell_type":"code","metadata":{"id":"p8nR3UTxezIF"},"source":["batch_size = 32 \n","epochs = 2\n","validation_split = 0.1 \n","number_of_images = len(training_batches) * (1 - validation_split)\n","\n","print(\"Number of images: \", number_of_images)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OwUSB37xfqXe"},"source":["end_step = np.ceil(number_of_images / batch_size).astype(np.int32) * epochs\n","print(\"End step: \", end_step)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p6_jZpQ1f-23"},"source":["pruning_params = {\n","      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=initial_sparsity,\n","                                                               final_sparsity=final_sparsity,\n","                                                               begin_step=begin_step,\n","                                                               end_step=end_step)\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qYqG6gaiIB6r"},"source":["Here we will use a magnitude-based method to remove the low saliency parameters of the neural network."]},{"cell_type":"code","metadata":{"id":"7dSZZIFU4iCi"},"source":["prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0mycL6m4ZxMg"},"source":["Here we define the model for pruning based on the original pre-treined model:"]},{"cell_type":"code","metadata":{"id":"8n2Sga55aZE3"},"source":["model_for_pruning = prune_low_magnitude(model, **pruning_params)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SrcoUcnUafjV"},"source":["It's necessary to recompile our model."]},{"cell_type":"code","metadata":{"id":"6zbXKuTKgsDX"},"source":["# `prune_low_magnitude` requires a recompile.\n","model_for_pruning.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2aVf0pXAZ9yJ"},"source":["Let's take a look at the layers of the original model and model for pruning."]},{"cell_type":"code","metadata":{"id":"qK0Sedq0eph7"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ClwxKLSdHi-V"},"source":["model_for_pruning.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sVK84pApa7Uv"},"source":["Finaly let's train our model "]},{"cell_type":"code","metadata":{"id":"vn2shY2Qa6BG"},"source":["logdir = tempfile.mkdtemp()\n","  \n","callbacks = [\n","  tfmot.sparsity.keras.UpdatePruningStep(),\n","  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n","]\n","\n","model_for_pruning.fit(training_batches,\n","                      batch_size=batch_size, \n","                      epochs=epochs, \n","                      validation_data=test_batches,\n","                      callbacks=callbacks)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zZTLX1V86w00"},"source":["Pruned model accuracy:"]},{"cell_type":"code","metadata":{"id":"Yz4Xhe5y6r6N"},"source":["_, original_model_accuracy = model.evaluate(test_batches, verbose=1)\n","_, pruned_model_accuracy = model_for_pruning.evaluate(test_batches, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MU5ot9iC7D5J"},"source":["print('Original model accuracy:', original_model_accuracy) \n","print('Pruned model accuracy:', pruned_model_accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XVgfoFi8dYOx"},"source":["Let's remove the unecessary variables used during the pruning process. "]},{"cell_type":"code","metadata":{"id":"Btz-xc2Yh5FB"},"source":["model_for_pruning.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UuAm9UQqdXg7"},"source":["model_to_save = tfmot.sparsity.keras.strip_pruning(model_for_pruning)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kzpPJbCe0B-_"},"source":["model_to_save.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"le2ZRILddNM1"},"source":["Let's convert and save the model"]},{"cell_type":"code","metadata":{"id":"QxLe0RwvdL_k"},"source":["converter = tf.lite.TFLiteConverter.from_keras_model(model_to_save)\n","pruned_whole_model = converter.convert()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mj0aHEpXd4vk"},"source":["Creating a folder for the pruned models"]},{"cell_type":"code","metadata":{"id":"IT93OMXdd0Zp"},"source":["import os\n","if not os.path.exists(\"pruned_models\"):\n","  os.makedirs(\"pruned_models\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T6dnFpNxd_26"},"source":["Saving"]},{"cell_type":"code","metadata":{"id":"ZfF8JMpLd_Dy"},"source":["with open(f'pruned_models/pruned_whole_model.tflite', 'wb') as f:\n","      f.write(pruned_whole_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9uCxx41SbGRj"},"source":["## Pruning just some layers"]},{"cell_type":"markdown","metadata":{"id":"EsZGsjSBb9jN"},"source":["* we can select just some layers to apply it and avoid this big accuracy drop."]},{"cell_type":"markdown","metadata":{"id":"gtotcl-tczDC"},"source":["Let's apply the pruning just in the Dense layers"]},{"cell_type":"code","metadata":{"id":"Sl86zg0KHZFz"},"source":["def apply_pruning_to_layers(layer):\n","  if isinstance(layer, tf.keras.layers.Dense):\n","    return tfmot.sparsity.keras.prune_low_magnitude(layer)\n","  return layer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CHstrJA9AZhu"},"source":["Defining the model for pruning "]},{"cell_type":"code","metadata":{"id":"IuANvat1Hc7a"},"source":["model_for_pruning = tf.keras.models.clone_model(\n","    model,\n","    clone_function=apply_pruning_to_layers,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ra6hUKQxdvFI"},"source":["Let's take a look at the layers of the model for pruning:"]},{"cell_type":"code","metadata":{"id":"a6pDRh3tcqVA"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xvBNySAtd2bX"},"source":["model_for_pruning.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F03PJaHdg3tm"},"source":["Training the new model, using the prune low magnitude."]},{"cell_type":"markdown","metadata":{"id":"W2rB-IiihR2R"},"source":["It's necessary to recompile our model:"]},{"cell_type":"code","metadata":{"id":"zzgvHrSFgvqb"},"source":["model_for_pruning.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dDCR5Yauhh1e"},"source":["Defining some parameters:"]},{"cell_type":"code","metadata":{"id":"2WiwbEBnhg0o"},"source":["batch_size = 32\n","epochs = 2\n","validation_split = 0.1 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bnRiz2mFhBwe"},"source":["logdir = tempfile.mkdtemp()\n","\n","callbacks = [\n","  tfmot.sparsity.keras.UpdatePruningStep(),\n","  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n","]\n","\n","model_for_pruning.fit(training_batches,\n","                      batch_size=batch_size, \n","                      epochs=epochs, \n","                      validation_data=test_batches,\n","                      callbacks=callbacks\n","                      )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dN00yhqqiaFY"},"source":["Evaluating the models:"]},{"cell_type":"code","metadata":{"id":"JjjrQ_F2hInK"},"source":["_, original_model_accuracy = model.evaluate(test_batches, verbose=1)\n","_, model_for_pruning_accuracy = model_for_pruning.evaluate(test_batches, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eIS1WmmaCCr0"},"source":["print('Original model accuracy:', original_model_accuracy) \n","print('Pruned model accuracy:', model_for_pruning_accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GK3c0rrng00o"},"source":["Removing unecessary variables "]},{"cell_type":"code","metadata":{"id":"7mo_dzTmgxIg"},"source":["model_to_save = tfmot.sparsity.keras.strip_pruning(model_for_pruning)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_FRAAumwgxIi"},"source":["Let's convert and save the model"]},{"cell_type":"code","metadata":{"id":"SBiP0kR8gxIj"},"source":["converter = tf.lite.TFLiteConverter.from_keras_model(model_to_save)\n","pruned_and_quantized_model = converter.convert()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"__Zz1uEfgxIo"},"source":["Saving"]},{"cell_type":"code","metadata":{"id":"jXrqjfFAgxIp"},"source":["with open(f'pruned_models/pruned_some_layers_model.tflite', 'wb') as f:\n","      f.write(pruned_and_quantized_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OibKWkj5ben-"},"source":["## Create a smaller model combining pruning and quantization"]},{"cell_type":"markdown","metadata":{"id":"7eWDmEGclPDg"},"source":["Converting the model with quantization:"]},{"cell_type":"code","metadata":{"id":"UBgJJ2TDj9Ie"},"source":["converter = tf.lite.TFLiteConverter.from_keras_model(model_to_save)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","pruned_and_quantized_model = converter.convert()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zqU0j2LqlQ3Y"},"source":["Saving the pruned and converted models:"]},{"cell_type":"code","metadata":{"id":"_Bki0KiglTdv"},"source":["with open(f'pruned_models/pruned_and_quantized_model.tflite', 'wb') as f:\n","      f.write(pruned_and_quantized_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W1eEN3CU7A89"},"source":["# TF Lite models\n","\n","---\n","## Original model\n","\n","> *original_model.tflite*  ➡ *11.858 KB*\n","\n","---\n","## Optimized models\n","\n","> *1. quantized_model_dynamic_range.tflite* ➡ *3.389 KB*\n","\n","> *2. quantized_model_int8.tflite* ➡ *3.454 KB*\n","\n","> *3. quantized_model_int8x16.tflite* ➡ *3.662 KB*\n","\n","> *4. quantized_model_float16.tflite* ➡ *5.971 KB*\n","\n","> *5. clustered_model.tflite* ➡ *11.858 KB*\n","\n","> *6. clustered_and_quantized_model.tflite* ➡ *3.389 KB*\n","\n","> *7. pruned_whole_model.tflite* ➡ *11.858 KB*\n","\n","> *8. pruned_some_layers_model.tflite* ➡ *11.858 KB*\n","\n","> *9. pruned_and_quantized_model.tflite* ➡ *3.389 KB*\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6ykeBV0TYhkT"},"source":["## How to evaluate the TF Lite model?\n","\n","As was said, the optimizations can affect the model accuracy, then, it's always necessary to evaluate the model that was optimized.\n","\n","You can analyse the accuracy of your model using the test data set.\n","\n","Reference:\n","\n","[Evaluating the TF Lite model](https://www.tensorflow.org/lite/performance/post_training_quant#evaluate_the_models)\n","\n","\n"]}]}